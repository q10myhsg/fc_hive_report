#nohup /home/apps/jdk/bin/java -cp ./lib/*:. com.fangcheng.createDataImpl.CreateData_PageImpl "201602">/home/hduser/project/Hive_FangCheng_Project/log.txt &
#nohup /home/apps/jdk/bin/java -cp ./lib/*:. com.fangcheng.createDataImpl.CreateData_DianpingImpl "201602">/home/hduser/project/Hive_FangCheng_Project/log.txt &
#mongodb数据库配置  123.57.4.152(内网id 10.172.216.138)  233(内网 10.172.228.111)
mongoip152=10.172.216.138
mongoport=27017
#mysql配置
jdbc.url=jdbc:mysql://192.168.1.134:3306/fangcheng_data_team
jdbc.username=fangcheng_admin 
jdbc.password=fc1234

#需要统计的地市  1,2,3,4,5,7,8,9,10,15,16,18,21,70,79,110,160,267,344
city=1,2,3,4,5,7,8,9,10,15,16,18,21,70,79,110,160,267,344
shoptype=10, 15, 20, 30, 45, 50, 55, 60, 65, 70, 80, 90
#--------------------------需要导入到hive的mongo基础数据信息-------------------------------
#文件分隔符,如果为空的话默认为\001
file_split=
#文件一
#page表      集合所在库+集合列表+生成方式(yyyyMM按月生成,yyyyMMdd按天生成)+生成周期(*表示每天都生成,02表示每月2号执行)page_parsed_20160108d
mongopage=dp_api_archive:page_parsed_201604d:yyyyMM:*
#文件名称的正则表达式     文件名正则表达式+生成方式(yyyyMM按月生成,yyyyMMdd按天生成)+生成周期(*表示每天都生成)+备份期数N-1(如3的话是备份2期)
page_name=city_page_\\d{6}\\.txt\:yyyyMM\:3
#文件二  api_20151205d    api_20160108d
mongodianping=dp_api_archive:api_201604d:yyyyMM:*
#文件名称的正则表达式     文件名正则表达式+生成方式(yyyyMM按月生成,yyyyMMdd按天生成)+生成周期(*表示每天都生成)+备份期数N-1(如3的话是备份2期)
dianping_name=city_.*?\\_dynamic_\\d{6}\\.txt\:yyyyMM\:3
#文件三
#adddate表      集合所在库+集合列表+生成方式(yyyyMM按月生成,yyyyMMdd按天生成)+生成周期(*表示每天都生成,02表示每月2号执行)
mongoadddate=dp_api_archive:api_history_add:yyyyMM:*
#文件名称的正则表达式     文件名正则表达式+生成方式(yyyyMM按月生成,yyyyMMdd按天生成)+生成周期(*表示每天都生成)+备份期数N-1(如3的话是备份2期)
adddate_name=api_history_add_\\d{6}\\.txt\:yyyyMM\:3

#原始数据文件的目录
filepath=/home/hduser/project/source_path
#文件加载到hive的目录
runpath=/home/hduser/project/run_path
#数据文件备份目录
backfilepath=/home/hduser/project/back_path


#--------------------------hive表-------------------------------------------------
#hive jdbc
hive_jdbc=jdbc:hive://localhost:10000/default
#hive中的page表
hive_page_table=hive_page
hive_dianping_table=hive_dianping
hive_adddate_table=hive_dianping_adddate

hqlid=dianping_filter,page_filter,dianping_page,dianping_page_temp,dianping_adddate_temp,dianping_adddate_temp2,dianping_adddate,dianping_transdate,dianping_change,city_brand1,city_brand2,brand_inmallid,brand_inmallname,brand_tag1,brand_tag2,dianping_final_temp,dianping_final,dianping_sort_temp,dianping_sort_max,dianping_sort
#设置job的配置文件
xml_path=./hive_config/service.xml
#hive语句存放文本路径
hql_path=./hive_config/config_hql.txt
#函数jar包目录
func_path=/home/hduser/project/function/function.jar
func_name=expend_shop,new_shop,mature_shop

#需要删除的分区表分区,hive表名+分区字段+时间类型+删除的批次(2表示当前日期的前两个月,如当前日期是20150915则是201507)
delname=hive_page_filter:dt:yyyyMM:2,hive_dianping_filter:dt:yyyyMM:2,hive_city_brand1:dt:yyyyMM:2,hive_city_brand2:dt:yyyyMM:2,hive_dianping_change:dt:yyyyMM:2,hive_page_change:dt:yyyyMM:2,hive_dianping_page:dt:yyyyMM:2,hive_dianping_brand1:dt:yyyyMM:2,hive_dianping_brand2:dt:yyyyMM:2
#------------------------sqoop导表--------------------------------------------------
sqoopsql=sqoop export --input-fields-terminated-by '\\001' --export-dir /home/hduser/hive_tmp/warehouse/hive_dianping_sort/dt\=yyyyMM --connect jdbc.url --username jdbc.username--password jdbc.password --table hive_dianping_final]yyyyMM]1
shellpage=/home/hduser/project/shellpath/
#程序停止目录,如果需要停止程序只需要在此目录下创建一个空文件即可
stoppath=/home/hduser/project/stop/

#-------------------------------------保留最原始点评adddate-------------------------------------------
api_db=dp_api_archive
api_collection=
#api_20160108d,api_20160102d,api_20151226d,api_20151219d,api_20151212d,api_20151205d,api_20151128d,api_20151121d,api_20151117d,api_20151107d,api_20151031d,api_20151024d,api_20151017d,api_20151010d,api_20151003d,api_20150926d,api_20150919d,api_20150912d,api_20150905d,api_20150828d,api_20150821d,api_20150814d,api_20150807d,api_20150730d,api_20150723d,api_20150716d,api_20150709d,api_20150702d,api_20150625d,api_20150618d,api_20150611d,api_20150604d,api_20150528d,api_20150521d,api_20150514d,api_20150507d,api_20150429d,api_20150422d,api_20150415d,api_20150408d,api_20150401d,api_20150325d,api_20150318d,api_20150311d
api_temp=api_temp_oup
api_history_add=api_history_add
api_history_close=api_history_close







